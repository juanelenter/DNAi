{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno = pd.read_csv(r\"../feno.txt\")\n",
    "geno = pd.read_csv(r\"../geno.txt\")\n",
    "\n",
    "pheno_names = [\"Cadmium_Chloride\", 'Congo_red', 'Cycloheximide', 'Diamide',  'Ethanol', 'Hydroquinone', 'Lithium_Chloride',\n",
    "              'Maltose', 'Neomycin', 'Tunicamycin', \"Galactose\", \"YNB:ph3\"]\n",
    "\n",
    "pheno_12 = pheno[pheno_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for filename in os.listdir('../params/gbm'):\n",
    "    if filename[-6:] == 'pickle':\n",
    "        with open('../params/gbm/' + filename, 'rb') as f:\n",
    "            results.append(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(feno, ratio):\n",
    "    \n",
    "    feno_n = feno.to_numpy()\n",
    "    N_random = np.random.permutation(feno.shape[0])\n",
    "    std = np.std(feno_n)\n",
    "    for n in N_random[:int(ratio*feno_n.shape[0])]:\n",
    "        if np.random.choice([0, 1]):\n",
    "            feno_n[n] = feno_n[n] + 2*std\n",
    "        else:\n",
    "            feno_n[n] = feno_n[n] - 2*std\n",
    "    \n",
    "    return feno_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_markers(geno, ratio):\n",
    "    \n",
    "    geno = geno.drop(columns = [\"Unnamed: 0\"]).values\n",
    "    geno_n = geno.copy()\n",
    "    N_or = geno.shape[1]\n",
    "    N_random = np.random.permutation(N_or)[:int(N_or*ratio)]\n",
    "    geno_n = np.delete(geno_n, N_random, axis = 1)\n",
    "    \n",
    "    print('{} of {} markers deleted.'.format(N_random.shape[0], N_or))\n",
    "\n",
    "    return geno_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "M = 4\n",
    "noise_ratios = np.array([5, 10, 20, 30, 40, 50, 75, 90])*0.01\n",
    "#del_ratios = np.array([10, 25, 50, 60, 70, 80, 90, 95, 99])*0.01\n",
    "del_ratios = np.arange(5, 99, step = 3)*0.01\n",
    "for name, y in pheno_12.iteritems():\n",
    "\n",
    "    print('Analyzing fenotype: ' + name + '.')\n",
    "    params = results[i][1]\n",
    "    n_estimators = params['n_estimators']\n",
    "    min_samples_split = params['min_samples_split']\n",
    "    min_samples_leaf = params['min_samples_leaf']\n",
    "    max_features = params['max_features']\n",
    "    max_depth = params['max_depth']\n",
    "    loss = params['loss']\n",
    "    learning_rate = params['learning_rate']\n",
    "    \n",
    "    missing_phenos = y[ y.isnull() ].index.values\n",
    "    y_c = y.copy()\n",
    "    y_c = y.drop(missing_phenos, axis = 0)\n",
    "    r2s = []\n",
    "    for (j, del_ratio) in enumerate(del_ratios):\n",
    "        geno_c = geno.copy()\n",
    "        geno_c = geno_c.drop(missing_phenos, axis = 0)\n",
    "        r2s_n = []\n",
    "        for k in np.arange(M):\n",
    "            geno_n = delete_markers(geno_c, del_ratio)\n",
    "            # ESTANDARIZANDO MAL !!\n",
    "            y_c = y_c - np.mean(y_c)\n",
    "            y_c = y_c/np.std(y_c)\n",
    "            #print(geno_n.shape)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(geno_n, y_c, test_size=0.3)\n",
    "\n",
    "            #X_train = X_train.drop(columns = [\"Unnamed: 0\"]).values\n",
    "            #X_test = X_test.drop(columns = [\"Unnamed: 0\"]).values\n",
    "\n",
    "            #y_train_std = (y_train - np.mean(y_train)) / np.std(y_train)\n",
    "            #y_test_std = (y_test - np.mean(y_train)) / np.std(y_train)\n",
    "        \n",
    "            gbm = GradientBoostingRegressor(n_estimators = n_estimators, min_samples_split = min_samples_split,\\\n",
    "                                        min_samples_leaf = min_samples_leaf, max_features = max_features,\\\n",
    "                                        max_depth = max_depth, loss = loss, learning_rate = learning_rate,\n",
    "                                        subsample = 1)\n",
    "            \n",
    "            gbm.fit(X_train, y_train)\n",
    "            \n",
    "            gbm_predictions = gbm.predict(X_test)\n",
    "            r2 = r2_score(y_test, gbm_predictions)\n",
    "\n",
    "            r2s_n.append(r2)\n",
    "\n",
    "        r2s.append(np.mean(np.array(r2s_n)))\n",
    "        print('Iteration {} of {} complete.'.format(j+1, del_ratios.shape[0]))\n",
    "    \n",
    "    clear_output()\n",
    "    with open('r2_gbm_del_{}.pickle'.format(name), 'wb') as f:\n",
    "        pickle.dump(r2s, f)\n",
    "        \n",
    "    i+=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[\n",
    "    1,  2,  3,  4],\n",
    "       [ 5,  6,  7,  8],\n",
    "       [ 9, 10, 11, 12]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4],\n",
       "       [ 5,  6,  7,  8],\n",
       "       [ 9, 10, 11, 12]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.delete(a, np.array([2, 3]), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2],\n",
       "       [ 5,  6],\n",
       "       [ 9, 10]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
