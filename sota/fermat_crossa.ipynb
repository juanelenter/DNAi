{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "IOcrQSr49vDW",
    "outputId": "1662154e-a7a5-4c12-e437-0ebac6ae71af"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multicore TSNE not found\n",
      "Loading data...\n",
      "Preprocessing...\n",
      "1 of 46 environments processed (Cadmium_Chloride) | Normalization type : og.\n",
      "2 of 46 environments processed (Caffeine) | Normalization type : og.\n",
      "3 of 46 environments processed (Calcium_Chloride) | Normalization type : og.\n",
      "4 of 46 environments processed (Cisplatin) | Normalization type : og.\n",
      "5 of 46 environments processed (Cobalt_Chloride) | Normalization type : og.\n",
      "6 of 46 environments processed (Congo_red) | Normalization type : og.\n",
      "7 of 46 environments processed (Copper) | Normalization type : og.\n",
      "8 of 46 environments processed (Cycloheximide) | Normalization type : og.\n",
      "9 of 46 environments processed (Diamide) | Normalization type : og.\n",
      "10 of 46 environments processed (E6_Berbamine) | Normalization type : og.\n",
      "11 of 46 environments processed (Ethanol) | Normalization type : og.\n",
      "12 of 46 environments processed (Formamide) | Normalization type : og.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-43855256eb50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m X_train, X_test, y_train, y_test, env_train, env_test = load_n_pre(\"../data/yeast/geno.txt\", \"../data/yeast/feno.txt\", \n\u001b[0;32m---> 15\u001b[0;31m                                                                       norm_mode=\"og\", test_size = .1)\n\u001b[0m",
      "\u001b[0;32m~/fing/Deep_DNA/dnai/sota/preprocess.py\u001b[0m in \u001b[0;36mload_n_pre\u001b[0;34m(geno_path, pheno_path, env_indxs, test_size, norm_mode, seed)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_env_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_env_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# standarize phenotype (envirorment)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from models import create_mlp, create_cnn\n",
    "from preprocess import load_n_pre\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from geno_2_img import *\n",
    "\n",
    "# load data\n",
    "test_size = .1\n",
    "X_train, X_test, y_train, y_test, env_train, env_test = load_n_pre(\"../data/crossa_wheat/geno_crossa.npy\", \"../data/crossa_wheat/feno_crossa.npy\", \n",
    "                                                                      norm_mode=\"og\", test_size = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "colab_type": "code",
    "id": "c_3RWe8KU7p8",
    "outputId": "c424996e-3b2a-4740-97d4-c2d174825c6a"
   },
   "outputs": [],
   "source": [
    "img_shape = (200, 200)\n",
    "X_train_img, X_test_img = transform_train_test(X_train, X_test, img_shape = img_shape, norm = \"whole\",\n",
    "                                               method = \"fermat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 601
    },
    "colab_type": "code",
    "id": "W6EOyizCOKFg",
    "outputId": "5cc41e3f-4387-4222-8f81-67fe8188e5b0"
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.figure(figsize = (10, 10))\n",
    "    plt.imshow(X_train_img[i, :, :], cmap = \"gray\")\n",
    "    plt.colorbar()\n",
    "    plt.savefig( f\"output/yeast_fermat_{i}\", transparent=True,dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uG5Wn6_t-BXn"
   },
   "outputs": [],
   "source": [
    "R2_nati = np.array([0.797, 0.250, 0.268, 0.338, 0.460, 0.504, 0.456, 0.529, \n",
    "           0.498, 0.412, 0.518, 0.350, 0.235, 0.399, 0.225, 0.336, \n",
    "           0.480, 0.568, 0.582, 0.711, 0.278, 0.519, 0.809, 0.255, \n",
    "           0.432, 0.614, 0.496, 0.383, 0.411, 0.424, 0.515, 0.634, \n",
    "           0.471, 0.636, 0.397, 0.552, 0.315, 0.516, 0.543, 0.195, \n",
    "           0.356, 0.556, 0.432, 0.711, 0.485, 0.495])\n",
    "def plot_learning(hist):\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(hist.history[\"loss\"])\n",
    "    plt.plot(hist.history[\"val_loss\"])\n",
    "    plt.legend([\"train\", \"val\"])\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"mse\")\n",
    "    plt.grid(axis = \"y\")\n",
    "    plt.title(\"Learning plot\")\n",
    "\n",
    "def test_results(model, X_test, env_test, y_test, R2_nati = R2_nati, max_env = 46):\n",
    "    \n",
    "    y_pred = model.predict({\"geno\" : X_test, \"env\" : env_test})\n",
    "    metrics = {\"r2\" : [],\n",
    "               \"best_r2_nati\" : R2_nati[[17, 18, 29, 37]],\n",
    "               \"mse\" : []}\n",
    "    for env in range(max_env):\n",
    "        y_pred_e = y_pred[np.where(env_test[:, env] == 1)].reshape((-1,))\n",
    "        y_test_e = y_test[np.where(env_test[:, env] == 1)].reshape((-1,))\n",
    "        metrics[\"r2\"].append(np.round(pearsonr(y_pred_e, y_test_e)[0]**2, 3))\n",
    "        metrics[\"mse\"].append(np.mean((y_pred_e - y_test_e)**2))\n",
    "    \n",
    "    return pd.DataFrame(metrics, index = [\"Lactate\", \"Lactose\", \"Sorbitol\", \"Xylose\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "FJu37V1G-GnI",
    "outputId": "b8dd628b-5105-4f68-e394-ca31f7ea72e7"
   },
   "outputs": [],
   "source": [
    "cnn = create_cnn(img_height = img_shape[0], img_width = img_shape[1], filters = [2, 4, 8, 16], \n",
    "                 kernel_sizes = [2, 4, 8, 10], strides = [2, 2, 2, 2], final_sizes = [8, 4], dropout = .25)\n",
    "\n",
    "Inp = layers.Input((env_train.shape[1], ))\n",
    "conc = layers.concatenate([Inp, cnn.output])\n",
    "\n",
    "x = layers.Dense(4, activation=\"relu\")(conc)\n",
    "x = layers.Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "model = keras.Model(inputs = [Inp, cnn.input], outputs = x)\n",
    "\n",
    "opt = optimizers.Adam(lr = 0.0005, decay = 1e-3/200, epsilon = .1)\n",
    "model.compile(loss = \"mse\", optimizer = opt)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "i4SIB_lFLyiJ",
    "outputId": "6ed7b384-6d6e-4964-8950-a6e24d839883"
   },
   "outputs": [],
   "source": [
    "h = model.fit(x = [env_train, X_train_img], y = y_train, \n",
    "              validation_data = ([env_test, X_test_img], y_test),\n",
    "\t            epochs = 300, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "bBmzWt5TSakV",
    "outputId": "c65bee57-460b-4d25-c458-137545649e60"
   },
   "outputs": [],
   "source": [
    "plot_learning(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "colab_type": "code",
    "id": "o-NNAcBLS-xt",
    "outputId": "27c13af0-accd-406d-fc11-ff42e0d2782e"
   },
   "outputs": [],
   "source": [
    "results = test_results(model, X_test_img, env_test, y_test, max_env = 4); results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1FUqTcUqpsag"
   },
   "outputs": [],
   "source": [
    "l_rand = h.history[\"val_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cupETvU3uI7l"
   },
   "outputs": [],
   "source": [
    "l_tsne = h.history[\"val_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "4j_Qn0JHUpmc",
    "outputId": "a6e719d7-a3ce-4eda-8a54-74ae9db3e99e"
   },
   "outputs": [],
   "source": [
    "h.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "colab_type": "code",
    "id": "BKw-Wg4mzINl",
    "outputId": "64900555-badc-4b32-9a1f-5c424c2d0d1b"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12.5, 7.5))\n",
    "for l in [l_rand, l_tsne, l_kpca]:\n",
    "  plt.plot(l)\n",
    "plt.grid(axis = \"y\")\n",
    "plt.title(\"validation loss per epoch\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"val. mse\")\n",
    "plt.legend([\"random\", \"tsne\", \"kpca\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VbUV8fhusUGz"
   },
   "outputs": [],
   "source": [
    "l_kpca = h.history[\"val_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UcbiKGRjU4Hr"
   },
   "outputs": [],
   "source": [
    "del(model)\n",
    "x = keras.layers.Flatten()(Res.output)\n",
    "x = keras.layers.BatchNormalization(axis = -1)(x)\n",
    "x = keras.layers.Dropout(rate = .33)(x)\n",
    "x = keras.layers.Dense(32, activation = \"relu\")(x)\n",
    "x = keras.layers.Dense(16, activation = \"relu\")(x)\n",
    "x = keras.layers.Dense(8, activation = \"relu\")(x)\n",
    "x = keras.layers.Dense(4, activation = \"relu\")(x)\n",
    "conc = keras.layers.concatenate([Inp, x])\n",
    "x = keras.layers.Dense(4, activation = \"relu\")(conc)\n",
    "x = keras.layers.Dense(1, activation = \"linear\")(x)\n",
    "\n",
    "model = keras.Model(inputs = [Inp, Res.input], outputs = x)\n",
    "\n",
    "opt = optimizers.Adam(lr = 0.0005, decay = 1e-3/200, epsilon = .1)\n",
    "model.compile(loss = \"mse\", optimizer = opt)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oco9_QbZbjbx"
   },
   "outputs": [],
   "source": [
    "h = model.fit(x = [env_train, X_train_res], y = y_train, \n",
    "              validation_data = ([env_test, X_test_res], y_test),\n",
    "\t            epochs = 100, batch_size = 64)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled7.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
